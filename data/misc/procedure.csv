"step","category","file","code","entity","description","action","reason"
"pre-process","trimming","data_pre_process.R","TR001","COLUMN","green16_frac, libert16_frac, other16_frac","trim","we will not consider these minority parties. Gary Johnson and Jill Stein did not win a single county so third parties will not affect largely the result between Democratic and Republican party. Nonetheless, we will create a other16_frac column just in case"
"pre-process","trimming","data_pre_process.R","TR002","COLUMN","all with suffix _frac2","trim","they are calculated by the author to just consider 2 major parties in the ratio, but since we want to group all other parties as one, we do not need this"
"pre-process","trimming","data_pre_process.R","TR003","COLUMN","all with prefix votes16_ except for votes16_trumpd and votes16_clintonh","trim","we will sum the votes of all third parties to votes16_other"
"pre-process","trimming","data_pre_process.R","TR004","COLUMN","name_prev, ST, County, State, votes, reporting, precincts, X, Y, X1","trim","they are of no use to our usage and merely left there in the dataset as tracers of the election scrapping algorithm that the author used, or they are merely duplicated of some other columns"
"pre-process","trimming","data_pre_process.R","TR005","COLUMN","At.Least.High.School.Diploma","trim","not surprisingly this and Less.Than.High.School sum to 100% and so we can count this as redundant"
"pre-process","trimming","data_pre_process.R","TR006","COLUMN","nearest county, temp, precip, temp_bins, lat_bins, lon_bins, precip_bins, elevation_bins, lon, lat, elevation","trim","trace or temporary features of the scraping algorithm used to mine weather data"
"pre-process","trimming","data_pre_process.R","TR007","COLUMN","all with suffix _TMAX, _TMIN, _TAVG, _PRCP, except for winter_PRCP and winter_TAVG","trim","we do not need all weather data, we will only keep winter data for the period of time during the election as this potentially affect the outcome of the election (e.g. due to bad weather, people cannot vote, etc.)"
"pre-process","trimming","data_pre_process.R","TR008","COLUMN","White, Black, Hispaic, Asian, Amerindian, Other, White_Asian","trim","duplicated to the other race features, probably used by the author for his socioeconomic factor calculations"
"pre-process","trimming","data_pre_process.R","TR009","COLUMN","CA, S, MAR, CFS, ACFS, MeanALC, MaxALC, Mixedness","trim","those are columns that the author computed in his paper, there are little knowledge of how he computed them as well as how to use them but they are calculated but on the demographics informations that we already have, so we can safely discard them"
"pre-process","trimming","data_pre_process.R","TR010","ROW","Alaska County (2000) and Oglala Lakota county (46102) and all rows where the county has no name, or no county FIPS code","trim","Alaska does not have the county system (they have boroughs) and thus we do not have their other demographic data based on county. Oglala Lakota is the Indian reservation area and we do not have most of their demographic data as well. As we use county FIPS code to match data while merging dataset, rows without county FIPS code should be discarded. Evidently, these rows and the rows for county without names have a lot of missing data and should be discarded"
"pre-process","editing","data_pre_process.R","ED001","COLUMN","winter_PRCP","divide by 100","the scraping algorithm did not divide the precipitation data by 100. This can be verified by looking into the weather scraping code of the author or by going to the weather data source."
"pre-process","editing","data_pre_process.R","ED002","COLUMN","winter_TAVG","divide by 10","the scraping algorithm did not divide the precipitation data by 10. This can be verified by looking into the weather scraping code of the author or by going to the weather data source"
"pre-process","adding","data_pre_process.R","AD001","COLUMN","other16_frac, votes16_others","add","these will represent the number of vote and the vote fraction of other parties in the 2016 election"
"pre-process","adding","data_pre_process.R","AD002","COLUMN","elec_rep16_win, elec_rep16_win, elec_rep16_win","add","this column indicates if Republican party wins the county in various election year. Essentially, we are considering converting this problem into a two-class problem as we realize that other parties did not win any county"
"pre-process","adding","data_pre_process.R","AD003","COLUMN","sex_ratio, age_dependency_ratio, median_age","add","some useful and typically-included demographic indicator concerning age and gender (in this step, we also update the median age data)"
"pre-process","adding","data_pre_process.R","AD004","COLUMN","life_expectancy","add","usuful healthcare and standard of living indicator"
"pre-process","adding","data_pre_process.R","AD005","COLUMN","Total.Population, voting_age_population","add","we update the total population and add in information regarding voting age population in order to calculate voting participation rate"
"pre-process","adding","data_pre_process.R","AD006","COLUMN","voting_power","add","each state owns different number of electoral votes which affect the result directly so it is intuitive for candicdate to focus his/her campaign and funding on certain area. This data cannot be computed from the 2016 results so we used the 2012 results instead"
"pre-process","adding","data_pre_process.R","AD007","COLUMN","voting_participation","add","this also cannot be computed from the 2016 result but by the 2012 result"
"pre-process","adding","data_pre_process.R","AD008","COLUMN","population_density","add","candidate might be interested in populous region to campaign"
"pre-process","updating","data_pre_process.R","UP001","COLUMN","Poor.physical.health.days, Poor.mental.health.days, Low.birthweight, Teen.births, Children.in.single.parent.households, Adult.smoking, Adult.obesity, Diabetes, Sexually.transmitted.infections, HIV.prevalence.rate, Uninsured, Unemployment, Violent.crime, Homicide.rate, Injury.deaths, Infant.mortality","update using 2016 dataset","update healthcare related data"
"pre-process","updating","data_pre_process.R","UP002","COLUMN","Median.Earnings.2010.dollars, Less.Than.High.School, At.Least.Bachelor.s.Degree, Graduate.Degree, School.Enrollment, White.not.Latino.Population, African.American.Population, Native.American.Population, Asian.American.Population, Population.some.other.race.or.races, Latino.Population, Children.Under.6.Living.in.Poverty, Adults.65.and.Older.Living.in.Poverty, Preschool.Enrollment.Ratio.enrolled.ages.3.and.4, Poverty.Rate.below.federal.poverty.threshold, Gini.Coefficient, Child.Poverty.living.in.families.below.the.poverty.line, Management.professional.and.related.occupations, Service.occupations, Sales.and.office.occupations, Farming.fishing.and.forestry.occupations, Construction.extraction.maintenance.and.repair.occupations, Production.transportation.and.material.moving.occupations","update using 2010 dataset","update various human-development related data. This is essentially to undo the compilation step of the original author when he averages 2009 and 2010 data"
"prepare","cleansing","data_prepare.R","HO001","ROW","Whitman County (53075)","trim","we find the state that has unreliable voting results based on the current number of remaining vote and the difference between the votes of 2 major parties"
"prepare","cleansing","data_prepare.R","HO002","ROW","voting_participation with value exceeding upper bound","clamp","we find that some county has higher voting participation rate than 100% which seems impossible but the reason is mainly due to how we derive this feature"
"prepare","trimming","data_prepare.R","TR011","COLUMN","name_16","trim","this feature is absolutely not needed: including it will be as bad as including couty FIPS code"
"prepare","trimming","data_prepare.R","TR012","COLUMN","dem08, rep08, total08, other08, dem12, rep12, total12, other12, votes16_trumpd, votes16_clintonh, total16, rep16_frac, dem16_frac, rep12_frac, rep08_frac, dem12_frac, dem08_frac, other12_frac, other08_frac, votes16_others, other16_frac","trim","we decided to choose our target as elec_rep16_win and so we can get rid of these features"
"prepare","trimming","data_prepare.R","TR013","COLUMN","rep08_win, Total.Population","trim","we can get rid of the 2008 result as it is extremely similar to the 2012 result so we can just use the 2012 result alone. As for the population, we find the better indicator in the same domain is population density so we can get rid of this feature"
"prepare","trimming","data_prepare.R","TR014","COLUMN","est_votes_remaining, voting_age_population","trim","these features are used to find the flipable county and now can be discarded"
"prepare","repairing","data_prepare.R","HM001","COLUMN","Low.birthweight, Teen.births, Sexually.transmitted.infections, HIV.prevalence.rate, Violent.crime, Homicide.rate, Injury.deaths, Infant.mortality","repair","predict the missing values for healthcare data from data of previous years"
"prepare","repairing","data_prepare.R","HM002","COLUMN","Less.Than.High.School, At.Least.Bachelor.s.Degree, Graduate.Degree, School.Enrollment, Adults.65.and.Older.Living.in.Poverty, Preschool.Enrollment.Ratio.enrolled.ages.3.and.4, Median.Earnings.2010.dollars","repair","predict the missing values for human-development data from data of previous years"
"prepare","repairing","data_prepare.R","HM003","COLUMN","winter_PRCP, winter_TAVG","repair","predict the missing values based on data of adjacent counties"
"prepare","repairing","data_prepare.R","HM004","COLUMN","winter_PRCP, winter_TAVG, Low.birthweight, Teen.births, Sexually.transmitted.infections, HIV.prevalence.rate, Violent.crime, Homicide.rate, Injury.deaths, Infant.mortality, Adults.65.and.Older.Living.in.Poverty, Preschool.Enrollment.Ratio.enrolled.ages.3.and.4, Median.Earnings.2010.dollars","repair","predict the missing values based on the average of the data from counties within the same state"
"prepare","repairing","data_prepare.R","HM005","COLUMN","winter_PRCP, winter_TAVG, HIV.prevalence.rate","repair","predict the missing values based on average of adjacent state (used when data for the whole state is missing)"
"prepare","feature-selecting","data_feature_rank.R","FS001","ALL","all","rank","using random forest, rank the features based on their importance"
"prepare","feature-selecting","data_feature_rank.R","FS002","ALL","all","rank","using correlation and entropy"
"prepare","feature-selecting","data_feature_rank.R","FS003","ALL","all","rank","create linear model and repeatedly remove the feature that contributes the least (or the most) to the model and rebuild the model, rank the features based on the order or removal"
"prepare","feature-selecting","data_feature_rank.R","FS004","ALL","all","rank","using various attribute search technique to build the best linear model, rank features based on the number of times they appear in the best models"
"prepare","feature-selecting","data_feature_rank.R","FS005","ALL","all","rank","using various attribute search technique to build the best decision tree (CART), rank features based on the number of times they appear in the best trees"
"prepare","feature-selecting","data_select.R","FS006","ALL","healthcare_life_expectancy, education_less_than_high_school, health_poor_physiscal_health_days, health_poor_mental_health_days, health_adult_smoking, health_teen_birth, poverty_child_living_in_families, poverty_below_federal_threshold, poverty_adult, poverty_children","principal component analyze","using both correlation and ranking score to determine features to be removed and proceed using PCA to reduce these weak features to fewer principal components"
"modelling","modelling","model_probe.R","MD001","ALL","all except elec_rep12_win and fips_state","tune","probe over a large range of values to see the suitable range for tuning the number k of nearest-neighbor classifier (knn)"
"modelling","modelling","model_probe.R","MD002","ALL","all except elec_rep12_win and fips_state","tune","probe over a large range of value to see the suitable range for tuning the number k of weighted nearest-neighbor classifier (kknn)"
"modelling","modelling","model_probe.R","MD003","ALL","all except elec_rep12_win and fips_state","tune","probe over a large number of possible hidden layers configuration for neural network"
"modelling","modelling","model_probe.R","MD004","ALL","all except elec_rep12_win and fips_state","tune","visualize the performance of the resuling model to identify the best tuning range for the computationally expensive algorithms"
"modelling","modelling","model_tune.R","MD005","ALL","all","tune","tune parameters for all the classifiers"
"modelling","modelling","model_tune.R","MD006","ALL","all except elec_rep12_win and fips_state","rank","attempt to find the best subset of categories/domains that could have been used for modelling"
